{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wild Card</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Bigram</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBigram(_queri):\n",
    "    hasil = []\n",
    "    for i in range(len(_queri)-1):\n",
    "        if i == 0:\n",
    "            hasil.append('$'+_queri[i])\n",
    "        else:\n",
    "            hasil.append(_queri[i] + _queri[i+1])\n",
    "            \n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wildCard(_queri):\n",
    "    queri = _queri.replace('*','')\n",
    "    bigram = generateBigram(queri)\n",
    "    \n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Koreksi Ejaan</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Kata Terisolasi</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import words #kamus inggris\n",
    "from nltk.metrics import * #hitung jarak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellingCorection(_word):\n",
    "    wordsSelected = identicalWord(_word)\n",
    "    \n",
    "    thresholdDistance = 3 #threshold\n",
    "    mostIdenticalWord = []\n",
    "    for i in wordsSelected: #check dengan levenshtaien\n",
    "        tempDistance = edit_distance(i, _word)\n",
    "        if tempDistance < thresholdDistance:\n",
    "            sortestDistance = tempDistance\n",
    "            mostIdenticalWord.append(i)\n",
    "            \n",
    "    return mostIdenticalWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identicalWord(_word):\n",
    "    wordLenght = len(_word)\n",
    "    wordsSelected = [] #word yang selisih panjang = 0\n",
    "    \n",
    "#     listOfWord = getListOfWord('hasil_inverted.txt')\n",
    "    \n",
    "    for word in listOfWordOfInvIndex: #tadinya listOfWord (yg di atas)\n",
    "        if abs(len(word) - wordLenght) == 0 and word[0] == _word[0]: #panjangnya sama dan huruf depan sama\n",
    "            wordsSelected.append(word)\n",
    "            \n",
    "    return wordsSelected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfWord(_path):\n",
    "    f = open(_path,\"r\")\n",
    "    words = f.read()\n",
    "    words = words.replace('\\t','')\n",
    "    listOfWord = words.split('\\n')\n",
    "    \n",
    "    return listOfWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = spellingCorection('for me')\n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pre-Procesing Queri</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(listOfWords):\n",
    "    for i in range(len(listOfWords)):\n",
    "        if listOfWords[i] != 'OR' and listOfWords[i] != 'AND' and listOfWords[i] != 'NOT':\n",
    "            listOfWords[i] = listOfWords[i].casefold()\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(listOfWords):\n",
    "    for i in range(len(listOfWords)):\n",
    "        listOfWords[i] = lemmatizer.lemmatize(listOfWords[i])\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(_queri):\n",
    "    listOfWord = _queri.split(' ')\n",
    "    \n",
    "    return listOfWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def stemming(listOfWords):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "#     stemmed = [stemmer.stem(word) for word in listOfWords]\n",
    "    for i in range(len(listOfWords)):\n",
    "        if listOfWords[i] != 'OR' and listOfWords[i] != 'AND' and listOfWords[i] != 'NOT':\n",
    "            listOfWords[i] = stemmer.stem(listOfWords[i])\n",
    "    \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def removeStopWord(listOfWords):\n",
    "    for i in listOfWords:\n",
    "        if i in stop_words:\n",
    "            listOfWords.remove(i)\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessingQuery(_query):\n",
    "    listOfWords = tokenize(_query)\n",
    "#     print('token : ',listOfWords)\n",
    "    listOfWords = caseFolding(listOfWords)\n",
    "#     print('case : ',listOfWords)\n",
    "    listOfWords = removeStopWord(listOfWords)\n",
    "#     print('remove : ',listOfWords)\n",
    "    listOfWords = stemming(listOfWords)\n",
    "#     print('stem : ',listOfWords)\n",
    "    listOfWords = lemmatization(listOfWords)\n",
    "#     print('lemma : ',listOfWords)\n",
    "    \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Main</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBoolean(_listOfWord, _bool):\n",
    "    boolIndex = []\n",
    "#     listOfWord = _query.split(' ')\n",
    "    for i in range(len(_listOfWord)):\n",
    "        if _listOfWord[i] == _bool:\n",
    "            boolIndex.append(i)\n",
    "            \n",
    "    return boolIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isWordInTerm(_listOfWord):\n",
    "    newListOfWord = []\n",
    "    temp = ''\n",
    "    for i in _listOfWord:\n",
    "        if i != 'OR' and i != 'AND' and i != 'NOT':\n",
    "            if i not in listOfWordOfInvIndex:\n",
    "#                 print(i)\n",
    "                try:\n",
    "                    temp = spellingCorection(i)[0]\n",
    "                    newListOfWord.append(temp)\n",
    "                except:\n",
    "                    print(\"No '\",i,\"' in Term\")\n",
    "#                     newListOfWord.append(temp)\n",
    "            else:\n",
    "                newListOfWord.append(i)\n",
    "        else:\n",
    "            newListOfWord.append(i)\n",
    "                \n",
    "    return newListOfWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryProcessing(_query):\n",
    "    andWord = []\n",
    "    orWord = []\n",
    "    notWord = []\n",
    "    \n",
    "    tempListOfWord = preProcessingQuery(_query) #pre processing query\n",
    "#     print('pre : ', tempListOfWord)\n",
    "    tempListOfWord = isWordInTerm(tempListOfWord) #koreksi query \n",
    "#     print('isword : ', tempListOfWord)\n",
    "    listOfWord = []\n",
    "    listOfWord = [tempListOfWord[0]]\n",
    "    \n",
    "    for i in range(1,len(tempListOfWord)): #mengubah NOT menjadi ~\n",
    "        if tempListOfWord[i] == 'NOT':\n",
    "            listOfWord.append('~' + tempListOfWord[i+1])\n",
    "        elif tempListOfWord[i-1] != 'AND' and tempListOfWord[i] != 'AND' and tempListOfWord[i-1] != 'NOT':\n",
    "            listOfWord.append('OR')\n",
    "            listOfWord.append(tempListOfWord[i])\n",
    "        elif tempListOfWord[i-1] != 'NOT':\n",
    "            listOfWord.append(tempListOfWord[i])\n",
    "        \n",
    "            \n",
    "    if '*' in _query:\n",
    "        query = wildCard(_query)\n",
    "    else:\n",
    "#         if 'AND' in _query:\n",
    "#             andIndex = findBoolean(listOfWord, 'AND')\n",
    "            \n",
    "#             for i in andIndex:\n",
    "#                 andWord.append(listOfWord[i-1])\n",
    "#                 andWord.append(listOfWord[i+1])\n",
    "                    \n",
    "#         if 'NOT' in _query:\n",
    "#             for i in listOfWord:\n",
    "#                 if i[0] == '~':\n",
    "#                     notWord.append(i)\n",
    "                    \n",
    "        if 'AND' not in _query and 'OR' not in _query:\n",
    "            orWord = listOfWord\n",
    "#         elif 'OR' in _query:\n",
    "#             orIndex = findBoolean(listOfWord, 'OR')\n",
    "#             for i in orIndex:\n",
    "#                 orWord.append(listOfWord[i-1])\n",
    "#                 orWord.append(listOfWord[i+1])\n",
    "#         else:\n",
    "#             for i in range(0,len(listOfWord)-1):\n",
    "#                 if listOfWord[i+1] != 'AND' and listOfWord[i] != 'AND':\n",
    "#                     orWord.append(listOfWord[i])\n",
    "#                     orWord.append(listOfWord[i+1])\n",
    "                \n",
    "#         print('OR : ',orWord)\n",
    "#         print('AND : ',andWord)\n",
    "#         print('NOT : ',notWord)\n",
    "    return listOfWord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manag', 'OR', 'minim', 'AND', 'manag']\n"
     ]
    }
   ],
   "source": [
    "listOfWordOfInvIndex = getListOfWord('hasil_inverted.txt')\n",
    "queryProcessing('makan minum AND mandi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makan AND minum\n",
    "makan AND NOT minum\n",
    "makan AND minum mandi\n",
    "makan minum AND mandi\n",
    "makan NOT minum AND mandi\n",
    "NOT makan minum AND mandi (x)\n",
    "makan OR NOT minum AND NOT main OR loker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
