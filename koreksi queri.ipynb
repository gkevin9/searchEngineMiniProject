{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wild Card</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Bigram</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateBigram(_queri):\n",
    "    hasil = []\n",
    "    for i in range(len(_queri)-1):\n",
    "        if i == 0:\n",
    "            hasil.append('$'+_queri[i])\n",
    "        else:\n",
    "            hasil.append(_queri[i] + _queri[i+1])\n",
    "            \n",
    "    return hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wildCard(_queri):\n",
    "    queri = _queri.replace('*','')\n",
    "    bigram = generateBigram(queri)\n",
    "    \n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Koreksi Ejaan</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Kata Terisolasi</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import words #kamus inggris\n",
    "from nltk.metrics import * #hitung jarak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spellingCorection(_word):\n",
    "    wordsSelected = identicalWord(_word)\n",
    "    \n",
    "    thresholdDistance = 3 #threshold\n",
    "    mostIdenticalWord = []\n",
    "    for i in wordsSelected: #check dengan levenshtaien\n",
    "        tempDistance = edit_distance(i, _word)\n",
    "        if tempDistance < thresholdDistance:\n",
    "            sortestDistance = tempDistance\n",
    "            mostIdenticalWord.append(i)\n",
    "            \n",
    "    return mostIdenticalWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identicalWord(_word):\n",
    "    wordLenght = len(_word)\n",
    "    wordsSelected = [] #word yang selisih panjang = 0\n",
    "    \n",
    "    listOfWord = getListOfWord('hasil_inverted.txt')\n",
    "    \n",
    "    for word in listOfWord:\n",
    "        if abs(len(word) - wordLenght) == 0 and word[0] == _word[0]: #panjangnya sama dan huruf depan sama\n",
    "            wordsSelected.append(word)\n",
    "            \n",
    "    return wordsSelected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getListOfWord(_path):\n",
    "    f = open(_path,\"r\")\n",
    "    words = f.read()\n",
    "    words = words.replace('\\t','')\n",
    "    listOfWord = words.split('\\n')\n",
    "    \n",
    "    return listOfWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['former']\n"
     ]
    }
   ],
   "source": [
    "a = spellingCorection('for me')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pre-Procesing Queri</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(listOfWords):\n",
    "    for i in range(len(listOfWords)):\n",
    "        listOfWords[i] = listOfWords[i].casefold()\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(listOfWords):\n",
    "    for i in range(len(listOfWords)):\n",
    "        listOfWords[i] = lemmatizer.lemmatize(listOfWords[i])\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(_queri):\n",
    "    listOfWord = _queri.split(' ')\n",
    "    \n",
    "    return listOfWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Main</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBoolean(_listOfWord, _bool):\n",
    "    boolIndex = []\n",
    "#     listOfWord = _query.split(' ')\n",
    "    for i in range(len(_listOfWord)):\n",
    "        if _listOfWord[i] == _bool:\n",
    "            boolIndex.append(i)\n",
    "            \n",
    "    return boolIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryProcessing(_query):\n",
    "    andWord = []\n",
    "    orWord = []\n",
    "    notWord = []\n",
    "    \n",
    "    tempListOfWord = _query.split(' ')\n",
    "    listOfWord = [tempListOfWord[0]]\n",
    "    \n",
    "    for i in range(1, len(tempListOfWord)):\n",
    "        if tempListOfWord[i] == 'NOT':\n",
    "            listOfWord.append('NOT' + tempListOfWord[i+1])\n",
    "        elif tempListOfWord[i-1] != 'NOT':\n",
    "            listOfWord.append(tempListOfWord[i])\n",
    "    \n",
    "    if '*' in _query:\n",
    "        query = wildCard(_query)\n",
    "    else:\n",
    "        if 'AND' in _query:\n",
    "            andIndex = findBoolean(listOfWord, 'AND')\n",
    "            \n",
    "            for i in andIndex:\n",
    "                andWord.append(listOfWord[i-1])\n",
    "                andWord.append(listOfWord[i+1])\n",
    "                    \n",
    "        if 'NOT' in _query:\n",
    "            for i in listOfWord:\n",
    "                if i[0] == 'N' and i[1] == 'O':\n",
    "                    notWord.append(i)\n",
    "                    \n",
    "        if 'AND' not in _query and 'OR' not in _query:\n",
    "            orWord = _query.split(' ')\n",
    "        elif 'OR' in _query:\n",
    "            orIndex = findBoolean(listOfWord, 'OR')\n",
    "            for i in orIndex:\n",
    "                orWord.append(listOfWord[i-1])\n",
    "                orWord.append(listOfWord[i+1])\n",
    "#         else:\n",
    "#             for i in range(1, len(listOfWord)):\n",
    "#                 if listOfWord[i] != 'AND':\n",
    "#                     orWord.append(listOfWord[i-1])\n",
    "#                     orWord.append(listOfWord[i])\n",
    "                \n",
    "        print('OR : ',orWord)\n",
    "        print('AND : ',andWord)\n",
    "        print('NOT : ',notWord)\n",
    "    print(listOfWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR :  ['makan', 'minum', 'mandi']\n",
      "AND :  []\n",
      "NOT :  []\n",
      "['makan', 'minum', 'mandi']\n"
     ]
    }
   ],
   "source": [
    "queryProcessing('makan minum mandi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makan AND minum\n",
    "makan AND NOT minum\n",
    "makan AND minum mandi\n",
    "makan minum AND mandi\n",
    "makan NOT minum AND mandi\n",
    "NOT makan minum AND mandi\n",
    "makan OR NOT minum AND NOT main OR loker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
