{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_column_arr(data_frame, field, field_arr):\n",
    "    list_f_arr = []\n",
    "    dict_hasil = {}\n",
    "    f_arr = data_frame[field_arr]\n",
    "    for i in f_arr:\n",
    "        deleted_simbol = i.replace(\" \",\"\").replace(\"'\", \"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        temp = deleted_simbol.split(\",\")\n",
    "        \n",
    "#         dict_hasil[term[i]] = num_doc\n",
    "        list_f_arr.append(temp)\n",
    "    dict_hasil = {field: data_frame[field], field_arr:list_f_arr }\n",
    "    df = pd.DataFrame(dict_hasil)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca File CSV yang Di Perlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   doc_num                                              token\n0        1  [0.39, 1, 750, 1, 780, 1, 850, 1, 870, 1, 875,...\n1        2  [15:02:20.00, 26-feb-1987, 55, activ, also, am...\n2        3  [13.5, 15:03:27.51, 26-feb-1987, 31, 7.5, appl...\n3        4  [-1, -20, 1, 11, 12, 15, 15:07:13.72, 2, 2.70,...\n4        5  [-1986, 0.99, 1, 1.24, 1.35, 1.56, 1.65, 1.92,...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_num</th>\n      <th>token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[0.39, 1, 750, 1, 780, 1, 850, 1, 870, 1, 875,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[15:02:20.00, 26-feb-1987, 55, activ, also, am...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[13.5, 15:03:27.51, 26-feb-1987, 31, 7.5, appl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[-1, -20, 1, 11, 12, 15, 15:07:13.72, 2, 2.70,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[-1986, 0.99, 1, 1.24, 1.35, 1.56, 1.65, 1.92,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_doc_num_token = pd.read_csv(\"doc_num_token.csv\")\n",
    "df_doc_num_token = conv_column_arr(df_doc_num_token,\"doc_num\",\"token\")\n",
    "df_doc_num_token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   term                                            doc_num\n0    -1  [0004, 0008, 0016, 0026, 0059, 0059, 0059, 005...\n1   -10                                             [0305]\n2  -100                                             [0427]\n3   -11                                             [0116]\n4  -110                                             [0427]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>doc_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>[0004, 0008, 0016, 0026, 0059, 0059, 0059, 005...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-10</td>\n      <td>[0305]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-100</td>\n      <td>[0427]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-11</td>\n      <td>[0116]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-110</td>\n      <td>[0427]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_token_doc_num = pd.read_csv(\"hasil_preprocessing.csv\")\n",
    "df_token_doc_num = conv_column_arr(df_token_doc_num, \"term\", \"doc_num\")\n",
    "df_token_doc_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "49088"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# menghitung jml token\n",
    "jml_token = 0\n",
    "for i in range(len(df_doc_num_token)):\n",
    "    jml_token += len(df_doc_num_token[\"token\"].iloc[i])\n",
    "jml_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi-fungsi untuk preprocessing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(txt):\n",
    "    list_hasil = txt.split(\" \")            \n",
    "    return list_hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNull(listOfWords): #['','','eat','food','','']\n",
    "    listOfWords = list(filter(None, listOfWords))\n",
    "    \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(listOfWords):\n",
    "    for i in range(len(listOfWords)):\n",
    "        listOfWords[i] = listOfWords[i].casefold()\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWord(listOfWords):\n",
    "    for i in listOfWords:\n",
    "        if i in stop_words:\n",
    "            listOfWords.remove(i)\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(listOfWords):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for word in listOfWords]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fungsi utama main preprocessing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_query(txt):\n",
    "    listOfWords = make_token(txt)\n",
    "    listOfWords = removeNull(listOfWords)\n",
    "    listOfWords = caseFolding(listOfWords)\n",
    "    listOfWords = removeStopWord(listOfWords)\n",
    "    listOfWords = stemming(listOfWords)\n",
    "    \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi utama menghitung Score dokumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitung_score(list_word,a):\n",
    "    list_rank = []\n",
    "    list_doc_num2 = []\n",
    "    df_hasil = []\n",
    "    for i in range(len(df_doc_num_token)):\n",
    "        rank = 1\n",
    "        doc = df_doc_num_token.iloc[i]\n",
    "        for j in list_word:\n",
    "            count = doc[\"token\"].count(j)\n",
    "            panjang_doc = len(doc[\"token\"])\n",
    "            p_doc =  (count/panjang_doc) * a\n",
    "#           ----------------------------------\n",
    "            temp = df_token_doc_num[df_token_doc_num[\"term\"] == j]\n",
    "#             print(i, temp)\n",
    "            count_m = len(temp.iloc[0][1])\n",
    "            p_m = (count_m/jml_token) * (1-a)\n",
    "            p = p_doc + p_m\n",
    "            rank *= p\n",
    "        list_rank.append(rank)\n",
    "        list_doc_num2.append(doc[\"doc_num\"])\n",
    "    dict_hasil = {\"doc_num\": list_doc_num2, \"rank\": list_rank}\n",
    "    df_hasil = pd.DataFrame(dict_hasil)\n",
    "    df_hasil = df_hasil.sort_values(by=[\"rank\"], ignore_index=True, ascending=False)\n",
    "    return df_hasil\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coba query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"1991\"\n",
    "q2 = \"Discounts\"\n",
    "q3 = \"accessed 9-Mar-87\"\n",
    "q4 = \"Analyst appeared\"\n",
    "q5 = \"Analyst analyst appeared\"\n",
    "q6 = \"Chairman closed the last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'discount'"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "q = pre_query(q2)\n",
    "search2 = ' '.join(map(str, q))\n",
    "search2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil = hitung_score(q,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_jawaban = {\n",
    "    \"1991\" : [31, 61, 70, 105, 190, 301, 422, 466],\n",
    "    \"discount\" : [77, 80, 97, 160, 195, 208, 215, 256, 488],\n",
    "    \"access 9-Mar-87\" : [32, 55, 110, 116, 134, 141, 142, 143, 144, 145, 146, 147, 148,\n",
    "                149, 150, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 261, \n",
    "                262, 263, 264, 265, 266, 267, 268, 269, 270, 321, 322, 323, 324, \n",
    "                325, 326, 327, 328, 329, 330, 348, 375, 381, 382, 383, 384, 385, \n",
    "                386, 387, 388, 389, 390, 441, 442, 443, 444, 445, 446, 447, 448,\n",
    "                449, 450],\n",
    "    \"analyst appear\" : [4, 8, 16, 18, 28, 45, 78, 95, 98, 111, 123, 133, 150, 180, 195, \n",
    "                235, 243, 262, 265, 292, 305, 320, 376, 399, 418, 459, 469, 493, \n",
    "                495, 496, 497],\n",
    "    \"analyst analyst appear\" : [4, 8, 16, 18, 28, 45, 78, 95, 98, 111, 123, 133, 150, 180, 195, \n",
    "                235, 243, 262, 265, 292, 305, 320, 376, 399, 418, 459, 469, 493, \n",
    "                495, 496, 497],\n",
    "    \"chairman close last\" : [1, 12, 18, 26, 28, 40, 43, 47, 52, 60, 61, 69, 78, 95, 98, 102, \n",
    "            107, 111, 114, 116, 133, 134, 135, 136, 138, 145, 148, 150, 153, \n",
    "            154, 155, 156, 161, 169, 174, 178, 180, 188, 194, 195, 197, 201, \n",
    "            203, 204, 207, 208, 214, 216, 224, 227, 230, 231, 232, 233, 234, \n",
    "            235, 242, 246, 254, 255, 256, 259, 261, 262, 263, 265, 267, 268, \n",
    "            269, 276, 279, 284, 288, 292, 303, 306, 314, 316, 318, 322, 324, \n",
    "            328, 330, 338, 339, 340, 343, 350, 355, 367, 371, 372, 375, 376, \n",
    "            378, 382, 383, 386, 392, 399, 404, 405, 409, 419, 420, 425, 430, \n",
    "            438, 439, 441, 444, 445, 446, 447, 448, 451, 454, 455, 457, 458, \n",
    "            463, 484, 488, 491, 492, 494, 495, 496, 498]\n",
    "}               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'1991': [31, 61, 70, 105, 190, 301, 422, 466], 'discount': [77, 80, 97, 160, 195, 208, 215, 256, 488], 'access 9-Mar-87': [32, 55, 110, 116, 134, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 348, 375, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450], 'analyst appear': [4, 8, 16, 18, 28, 45, 78, 95, 98, 111, 123, 133, 150, 180, 195, 235, 243, 262, 265, 292, 305, 320, 376, 399, 418, 459, 469, 493, 495, 496, 497], 'analyst analyst appear': [4, 8, 16, 18, 28, 45, 78, 95, 98, 111, 123, 133, 150, 180, 195, 235, 243, 262, 265, 292, 305, 320, 376, 399, 418, 459, 469, 493, 495, 496, 497], 'chairman close last': [1, 12, 18, 26, 28, 40, 43, 47, 52, 60, 61, 69, 78, 95, 98, 102, 107, 111, 114, 116, 133, 134, 135, 136, 138, 145, 148, 150, 153, 154, 155, 156, 161, 169, 174, 178, 180, 188, 194, 195, 197, 201, 203, 204, 207, 208, 214, 216, 224, 227, 230, 231, 232, 233, 234, 235, 242, 246, 254, 255, 256, 259, 261, 262, 263, 265, 267, 268, 269, 276, 279, 284, 288, 292, 303, 306, 314, 316, 318, 322, 324, 328, 330, 338, 339, 340, 343, 350, 355, 367, 371, 372, 375, 376, 378, 382, 383, 386, 392, 399, 404, 405, 409, 419, 420, 425, 430, 438, 439, 441, 444, 445, 446, 447, 448, 451, 454, 455, 457, 458, 463, 484, 488, 491, 492, 494, 495, 496, 498]}\n"
    }
   ],
   "source": [
    "print(dict_jawaban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[77, 80, 97, 160, 195, 208, 215, 256, 488]"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "get = dict_jawaban.get(search2)\n",
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'jawaban1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fcf797ddd99c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mteratas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_hasil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjawaban1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"doc_num\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'jawaban1' is not defined"
     ]
    }
   ],
   "source": [
    "teratas = df_hasil.head(len(jawaban1)).sort_values(by=[\"doc_num\"], ignore_index=True, ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'teratas' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-dd75c0205713>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhasil_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mteratas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"doc_num\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msalah\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhasil_query\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjawaban1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'teratas' is not defined"
     ]
    }
   ],
   "source": [
    "hasil_query = teratas[\"doc_num\"]\n",
    "salah = []\n",
    "\n",
    "for i in hasil_query:\n",
    "    if int(i) not in jawaban1:\n",
    "        salah.append(i)\n",
    "        \n",
    "len(salah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'teratas' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-550e74260902>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mteratas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'teratas' is not defined"
     ]
    }
   ],
   "source": [
    "teratas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, url_for, redirect, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(search, res):\n",
    "    res2 = int(res)\n",
    "    list_hasil = []\n",
    "    list_score = []\n",
    "    q = pre_query(search)\n",
    "    df_hasil = hitung_score(q,0.1)\n",
    "    for i in range(0, res2):\n",
    "        list_hasil.append(df_hasil.iloc[i][\"doc_num\"])\n",
    "        list_score.append(df_hasil.iloc[i][\"rank\"])\n",
    "    return list_hasil, list_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText(file):\n",
    "    words = []\n",
    "    f = open(file, 'r') #open file\n",
    "    text = f.read()    \n",
    "    f.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atribut(doc_id):\n",
    "    int_doc_id = int(doc_id)\n",
    "    str_doc_id = str(int_doc_id)\n",
    "    n = 4 - len(str_doc_id)\n",
    "    doc = (\"0\"*n) + str_doc_id\n",
    "    file_path = \"DataRouter\\\\Doc\" + doc + \".txt\"\n",
    "    \n",
    "    txt = readText(file_path)\n",
    "    \n",
    "    titlePattern = \"<TITLE>(.+)</TITLE>\"\n",
    "    title = re.findall(titlePattern, txt)[0]\n",
    "    \n",
    "    datePattern = \"<DATE>(.+)</DATE>\"\n",
    "    date = re.findall(datePattern, txt)[0]\n",
    "    \n",
    "    bodyPattern = \"<BODY>((.+\\s+)+)</BODY>\"\n",
    "    body = re.findall(bodyPattern, txt)[0]\n",
    "    print(body)\n",
    "    \n",
    "    return title, date, body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PUNYA BONTENG TF-IDF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchQuery(_dir, _query):\n",
    "    file = open(_dir,'r')\n",
    "    \n",
    "    listQuery = pre_query(_query)\n",
    "    \n",
    "    dictOfQuery = {}\n",
    "    textPerLine = file.readlines()\n",
    "    for line in textPerLine:\n",
    "        temp = line.split('\\t')\n",
    "        if temp[0] in listQuery:\n",
    "            addLineToDict(dictOfQuery, line)\n",
    "            \n",
    "#     for i in dictOfQuery:\n",
    "#         print(i,' : ',dictOfQuery[i])\n",
    "#     print('=======================')\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    dictOfRank = computeRank(dictOfQuery, listQuery)\n",
    "    \n",
    "    return dictOfRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLineToDict(_dict, _line):\n",
    "    tempList = _line.split('\\t')\n",
    "    term = tempList[0]\n",
    "    \n",
    "    \n",
    "    termWeigth = tempList[1]\n",
    "    termWeigth = termWeigth.replace(';\\n','')\n",
    "    termWeigth = termWeigth.split(';')\n",
    "    listTermTemp = []\n",
    "    for i in termWeigth:\n",
    "        i = i.replace('[','')\n",
    "        i = i.replace(']','')\n",
    "        i = i.replace(' ','')\n",
    "        i = i.split(',')\n",
    "        i = [int(i[0]),float(i[1])]\n",
    "\n",
    "        listTermTemp.append(i)\n",
    "        \n",
    "    _dict[term] = listTermTemp\n",
    "    \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRank(_dictTerm, _query):\n",
    "    dictQuery = countQuery(_query)\n",
    "    dictSumOfSim = {}\n",
    "    dictSumWeigthOfSim = {}\n",
    "#     print(dictQuery)\n",
    "    for i in _dictTerm:\n",
    "        ni = len(_dictTerm[i])\n",
    "        countWq = countWeigth(ni, dictQuery[i])\n",
    "#         print(countWq)\n",
    "        for k in _dictTerm[i]:\n",
    "            if k[0] in dictSumOfSim:\n",
    "                dictSumOfSim[k[0]] += k[1]**2 \n",
    "            else:\n",
    "                dictSumOfSim[k[0]] = k[1]**2\n",
    "                \n",
    "            if k[0] in dictSumWeigthOfSim:\n",
    "                dictSumWeigthOfSim[k[0]] += countWq * (k[1]**2) \n",
    "            else:\n",
    "                dictSumWeigthOfSim[k[0]] = countWq * (k[1]**2)\n",
    "                \n",
    "#     print(dictSumOfSim)\n",
    "#     print(dictSumWeigthOfSim)\n",
    "                \n",
    "    dictSqrtOfSim = findSqrt(dictSumOfSim)\n",
    "    \n",
    "    dictOfRank = findRank(dictSqrtOfSim, dictSumWeigthOfSim)\n",
    "    \n",
    "    return dictOfRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countQuery(_query):\n",
    "    dictOfQuery = {}\n",
    "    for i in _query:\n",
    "        if i in dictOfQuery:\n",
    "            dictOfQuery[i] += 1\n",
    "        else:\n",
    "            dictOfQuery[i] = 1\n",
    "            \n",
    "    return dictOfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRank(_dictSqrt, _dictWeigth):\n",
    "#     print('sqrt : ',_dictSqrt)\n",
    "#     print('weigth : ',_dictWeigth)\n",
    "    dictOfRank = {}\n",
    "    for i in _dictSqrt:\n",
    "        dictOfRank[i] = (_dictWeigth[i]/_dictSqrt[i])\n",
    "        \n",
    "    return({k: v for k, v in sorted(dictOfRank.items(), key=lambda item: item[1], reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def findSqrt(_dict):\n",
    "    for i in _dict:\n",
    "        _dict[i] = math.sqrt(_dict[i])\n",
    "    \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWeigth(_ni, _fij):\n",
    "    \n",
    "    file = open('sum_of_file.txt','r')\n",
    "    sumOfFile = int(file.read())\n",
    "    file.close()\n",
    "    \n",
    "    tf = computeTFLog(_fij)\n",
    "    idf = countIDF(sumOfFile, _ni)\n",
    "    weigth = tf * idf\n",
    "    weigth = weigth**2\n",
    "    \n",
    "    return weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#tf = 1 + log(i,j)\n",
    "def computeTFLog(_fi):\n",
    "    return 1 + math.log(_fi,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#idf = log(N/ni)\n",
    "def countIDF(_N, _ni):\n",
    "#     print('N : ',_N)\n",
    "#     print('_ni : ',_ni)\n",
    "    return math.log(1+(_N/_ni),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--- 0.03301882743835449 seconds ---\nRank :  {97: 510.75683569545686, 80: 395.175431406038, 77: 197.587715703019, 160: 197.587715703019, 195: 197.587715703019, 208: 197.587715703019, 215: 197.587715703019, 256: 197.587715703019, 488: 33.92396659928883}\n"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "rank = searchQuery('tf-idf.txt', 'Discount')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Rank : ', rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(rank, res):\n",
    "    res2 = int(res)\n",
    "    doc = []\n",
    "    score = []\n",
    "    doc2 = []\n",
    "    score2 = []\n",
    "    for x in rank:\n",
    "        doc.append(x)\n",
    "        score.append(rank[x])\n",
    "    if len(doc) > res2:\n",
    "        for i in range(0, res2):\n",
    "            doc2.append(doc[i])\n",
    "            score2.append(score[i])\n",
    "        return doc2, score2\n",
    "    else:\n",
    "        return doc, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calRecall(hasil, kunci):\n",
    "    list_match = []\n",
    "    for i in range(0,len(kunci)):\n",
    "        for j in range(0,len(hasil)):\n",
    "            if kunci[i] == hasil[j]:\n",
    "                list_match.append(hasil[j])\n",
    "\n",
    "    recall = 100 * (len(list_match)/len(kunci))\n",
    "    return recall            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calPrecision(hasil, kunci):\n",
    "    list_match = []\n",
    "    for i in range(0,len(kunci)):\n",
    "        for j in range(0,len(hasil)):\n",
    "            if kunci[i] == hasil[j]:\n",
    "                list_match.append(hasil[j])\n",
    "\n",
    "    precision = 100 * (len(list_match)/len(hasil))\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>================</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "will move (ahead with the daily).... This\\nis not definite but i think we will,\" he said, adding that he\\nplans to announce a decision early next week.\\n    Quebecor, which had revenues of 446 mln Canadian dlrs last\\nyear and profit of 16.2 mln dlrs, already publishes three daily\\nnewspapers, including the tabloid Le Journal de Montreal, the\\nsecond-largest circulation paper in Canada.\\n    A new daily would give Montreal its second English-\\nlanguage paper and its sixth daily newspaper, making the city\\nthe most crowded metropolitan newspaper market in North\\nAmerica, analysts have said.\\n    Peladeau said market studies have indicated a new English\\nlanguage tabloid would have circulation of 50,000 within six\\nmonths. He said he is waiting to determine whether the new\\nventure would have the support of major advertisers.\\n    Peladeau, who together with family members owns about 55\\npct of Quebecor, said he has recieved offers from the heads of\\ntwo major Canadian companies who are interested in the project\\nbut has not decided whether he would take partners in the\\nnewspaper venture.\\n    He said he would consider launching the newspaper with one\\nof the companies as a prelude to other joint ventures.\\n    \"It would be the possibility of doing something else in the\\nshort term,\" Peladeau said.\\n    Peladeau said the joint acquisition of Donohue with Robert\\nMaxwell\\'s British Printing and Communications Corp plc &lt;BPCL.L>\\ndoes not mean Quebecor will have to hold off on other projects.\\n    Peladeau and Maxwell\\'s companies teamed up to buy the stake\\nin Donohue, which resulted in Quebecor buying 51 pct of the\\ngovvernment\\'s stake for about 165 mln Canadian dlrs and British\\nprinting acquiring the other 49 pct.\\n    \"In 1976 or 77 there was a tremendous shortage of\\nnewsprint. There were days when we didn\\'t have enough paper to\\nprint the paper,\" Peladeau said. \"When I lived that, I said to\\nmyself...next time we\\'ll be ready.\"\\n    Peladeau said most of Donohue\\'s current total newsprint\\ncapacity however, is already committed to other buyers.\\n    Quebecor uses about 100,000 metric tons of newsprint a year\\nand Maxwell\\'s company, which publishes Britain\\'s Daily Mirror\\nnewspaper, uses about 200,000 tonnes.\\n    Peladeau said even with a new 170 mln dlr paper machine, 49\\npct owned by the New York Times, (NYT.A), adding to Donohue\\'s\\n540,000 metric tonne capacity this fall, the companies will\\nhave to install another paper machine at Amos, Quebec, or build\\nanother mill to meet their demands .\\n    He said a new mill, which would produce either newsprint or\\nother types of paper, would cost 400-500 mln dlrs and could be\\non stream in two years. He said a mill in Matane, a depressed\\narea with high unemployment, would be heavily subsidized by the\\ngovernment.\\n    Peladeau said he is interested in further joint ventures\\nwith Maxwell\\'s company, either in the newspaper market in\\nFrance or in the U.S., where the company owns two large\\nprinting plants and is looking to expand its newspaper empire.\\n    He said Maxwell\\'s sons, who are French citizens, would\\nprovide an entree into the French market, where foreigners are\\nprevented from buying newspapers. Peladeau said he would\\nconsider either buying into or starting daily newspapers in\\nFrance or the U.S.\\n    Quebecor is also in the process of expanding its chain of\\nabout 40 weekly newspapers, with the possible acquisition of\\ntwo groups of weekly newspapers in the U.S., and is negotiating\\nthe acquisition of two weekly newspaper chains in Canada,\\nPeladeau said.\\n    He said the company may consider starting daily newspapers\\nin two small Quebec cities and buying radio stations in the\\nprovince.\\n    Peladeau said Quebecor may also consider trading in its\\nlisting on the American stock exchange for a New York Stock\\nExchange listing.\\n', 'Exchange listing.\\n')\n('CitiCorp &lt;CCI> appears to be digging\\nin its heels for tough negotiations over the billions of\\ndollars in loans that Brazil owes to money center banks, Wall\\nStreet analysts said.\\n    \"I view it as pre-negotiation posturing,\" said analyst\\nCarole Berger of Cyrus J. Lawrence Inc, referring to both\\nBrazil and Citicorp. Brazil recently stopped paying interest on\\nits commercial bank debt. Today, CitiCorp said its first\\nquarter income would be reduced by 50 mln dlrs after tax if it\\nlists the loans as non-performing status.\\n    Citicorp filed an 8-K form with the Securities and Exchange\\nCommission, indicating a material change in its financial\\nsituation. \"Citicorp is saying you can\\'t scare us with threats,\\nwe\\'ll make your loans non-performing right now,\" Berger said.\\n    The loans have to be treated as non-performing after 90\\ndays without a payment. CitiCorp said only that the situation\\nwill be reviewed at the end of the current quarter.\\n    Berger asserted that Brazil is doing its own politicking by\\ntalking to U.S. regulators and trying to drive a wedge between\\nU.S. and European banks.\\n    Analyst Lawrence Cohn of Merrill Lynch and Co said it is\\nunlikely the situation will be resolved until the second half\\nof this year.\\n    \"Ultimately the Brazilians are going to have to pay up on\\nall the interest they owe,\" Cohn said. \"The real issue is the\\nrescheduling of debt terms.\\n    Another question is whether or not the International\\nMonetary Fund can help Brazil with a new austerity program.\\n    Stocks of money center banks were mostly down fractions in\\nlate dealings. One trader most stocks in the group bounced off\\ntheir lows by midday as investors took the news in stride.\\n    Cohn said the bank stocks may be risky until numbers on\\nnon-performing loans are reported for each bank. But he said\\ninvestors looking ahead six to 12 months might want to buy at\\npresent levels for the \"tremendous fundamental values\" in the\\ngroup.\\n    Analyst Robert Gordon of Shearson Lehman Brothers Inc said\\nManufacturers Hanover Corp &lt;MHC) has the greatest exposure to\\nBrazilian loans of any New York bank, in terms of percentage of\\nearnings. He said his only two recommendations currently among\\nNew York banks are J.P. Morgan and Co &lt;JPM> and Bankers Trust\\nCo &lt;BT> which happen to have the least exposure.\\n    Gordon said his positive opinion on J.P. Morgan and Bankers\\nTrust was not merely a response to the fact that the two have\\nlower exposure to Brazilian loans than other banks. \\n    In fact he said there\\'s a chance those banks could get more\\ninvolved in the future. He noted that Morgan has already set up\\na brokerage subsidiary to deal in loans to less developed\\ncountries.\\n    \"I don\\'t see any reason to change full year earnings\\nestimates, said Frederick Meinke, analyst at E.F. Hutton Co. He\\nthinks the confrontation with Brazil could end in a replay of a\\nsituation that occurred with Argentina in 1984 and 1985.\\n    Meinke noted that in the case of Argentina the loans became\\nnon-accruing for a couple of quarters but then when the banks\\ncame to an agreement with Argentina all the back interest was\\npaid. \"What it did was distort the quarterly earnings pattern,\"\\nhe said.\\n    He said in the case of Brazil write-offs of loans is a\\nworst-case outcome which is highly unlikely. He noted that\\nBrazil is a country with a diversified economy, going through\\nsome economic upheaval after the transition from a military to\\na civilian government.\\n    \"The countries of Latin America have too much debt relative\\nto their ability to service it,\" said John Mason of\\nInterstate Securities. \"We\\'ve been fiddling around with these\\nproblems for five years and the hour is growing late.\"\\n    He said up to now the banks have reduced their spreads, cut\\ninterest rates internally and extended maturities and none of\\nthese measures has been enough. He expects re-classification of\\nas much as a third of the loans as non-accruing and he sees\\npartial write downs of some loans.\\n    Nevertheless Mason thinks the money center bank stocks \\ncould be poised for a short term rally.\\n    A spokesman at First Chicago Corp &lt;FNB> said it is\\npremature to put Brazil\\'s loans on a cash basis. \"It is our\\nexpectation that economic development will allow Brazil to meet\\nits debt,\" a spokesman said.\\n    Bankers Trust in New York said it would be premature to\\nmake a decision. Several other banks queried by Reuters said\\nmuch the same thing.\\n    A spokesman at Manufacturers Hanover noted that of 2.3\\nbillion dlrs in loan exposure to Brazil only 1.3 billion is\\nsubject to Brazil\\'s unilateral moratorium on repayment of\\ninterest.\\n', 'interest.\\n')\n127.0.0.1 - - [12/May/2020 09:37:11] \"\u001b[37mGET /search HTTP/1.1\u001b[0m\" 200 -\n[2020-05-12 09:37:23,042] ERROR in app: Exception on /search [POST]\nTraceback (most recent call last):\n  File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n    reraise(exc_type, exc_value, tb)\n  File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n    raise value\n  File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"C:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n    return self.view_functions[rule.endpoint](**req.view_args)\n  File \"<ipython-input-40-12bce1d07313>\", line 31, in search\n    rec = calRecall(hasil, dict_jawaban.get(search2))\n  File \"<ipython-input-38-191b2fea183b>\", line 3, in calRecall\n    for i in range(0,len(kunci)):\nTypeError: object of type 'NoneType' has no len()\n127.0.0.1 - - [12/May/2020 09:37:23] \"\u001b[1m\u001b[35mPOST /search HTTP/1.1\u001b[0m\" 500 -\n('The Tower Commission report, which\\nsays President Reagan was ignorant about much of the Iran arms\\ndeal, just about ends his prospects of regaining political\\ndominance in Washington, political analysts said.\\n    \"This is certification of incompetence,\" private political\\nanalyst Stephen Hess told Reuters in commenting on the Tower\\nreport made public today.\\n    \"It\\'s as if he went before a professional licensing board\\nand was denied credentials.\"\\n    In one of the most direct criticisms, board chairman John\\nTower, a longtime Reagan supporter and former Republican\\nsenator from Texas, told a press conference, \"The president\\nclearly did not understand the nature of this operation.\"\\n    The report, which lent credence to widespread opinion in\\nWashington that Reagan is not in full command of the\\ngovernment, was particularly damaging because it was prepared\\nby a board of the Republican president\\'s own choosing.\\n    The three-member panel made up of Tower, former National\\nSecurity Adviser Brent Scowcroft and former Secretary of State\\nEdmund Muskie, does not carry the partisan taint of criticism\\nfrom a Congress controlled by the Democratic party.\\n    \"We\\'re falling by our own hand,\" said one Republican\\npolitical strategist. \"What can we say except \\'we\\'re sorry, we\\nwon\\'t do it again\\'?\"\\n    The strategist, who works for one of his party\\'s top 1988\\npresidential contenders and asked not to be identified, said\\nthe report was like \"an anvil falling on us.\"\\n    Hess, with the Brookings Institution public policy study\\ngroup, said the report is the final blow to Reagan\\'s hopes of\\nregaining the upper hand he once had in dealings with Congress,\\nthe press and the Washington bureaucracy.\\n    The report may also undermine the standing of Defense\\nSecretary Caspar Weinberger and Secretary of State George\\nShultz, who the report suggests were more interested in keeping\\ntheir own skirts clean than supporting the president.\\n    \"They protected the record as to their own positions on this\\nissue. They were not energetic in attempting to protect the\\npresident from the consequences,\" it said.\\n    White House chief of staff Donald Regan and former Central\\nIntelligence Agency Director William Casey also received strong\\ncriticism, but the blows were expected in their cases.\\n    Regan, expected to resign or be fired shortly, was savaged\\nfor allegedly failing both to help Reagan conduct the Iran\\ninitiative and to avoid \"chaos\" in the disclosure process.\\n    Casey, who underwent surgery for removal of a cancerous\\nbrain tumor in December, had already resigned for health\\nreasons last month.\\n    \"This is a story about people who came up somewhat short of\\nbeing heroes,\" Tower told reporters.\\n    While Reagan retains considerable constitutional powers,\\nincluding command of the armed forces and the right to veto\\nlegislation, analysts say it will be difficult for him to\\nretake control of the country\\'s policy agenda -- particularly\\nwith Congress controlled by the Democrats.\\n    The crucial remaining question, they said, is whether the\\nman in the street will forsake Reagan over the affair.\\n    Although his job approval rating has fallen as much as\\ntwenty percentage points in some opinion polls since the arms\\ndeal with Iran became public last November, his personal\\npopularity is still relatively high.\\n    A Los Angeles Times poll released earlier this week showed\\nthat just 37 pct of those surveyed thought Reagan was in\\ncontrol of the government, but 55 pct still thought he was\\ndoing a good job as president.\\n    American Enterprise Institute analyst William Schneider, a\\nDemocrat, says Reagan\\'s loss of support among Washington power\\nbrokers could be offset by continued backing of the public.\\n    \"In the past, he has been able to go around the power elite\\nby appealing directly to the public,\" Schneider said.\\n    Reagan will again plead his case that way in a televised\\naddress next week.\\n    But one top Republican strategist warned against expecting\\na dramatic turnaround.\\n    \"The White House has to avoid building expectations that\\ncannot be met,\" said the strategist, who requested anonymity.\\n\"They have to recognize there is no quick fix.\"\\n    Analysts also point out that Reagan\\'s personal popularity\\nhas not always translated into public backing for his policies.\\n    They note he was dramatically rebuffed in last November\\'s\\nelections when voters rejected his appeals and restored control\\nof the Senate to the Democrats.\\n', 'of the Senate to the Democrats.\\n')\n('Iraq said its forces killed or wounded\\n15,000 Iranian Revolutionary Guards as they crushed a new\\nIranian offensive near the strategic port city of Basra.\\n    A high command war communique said four Revolutionary\\nGuards divisions attacked Iraqi positions east of Basra on the\\nGulf War southern front, but they were fully crushed by noon\\n(0900 GMT).\\n    Adbul-Jabbar Mohsen, chief of the defence ministry\\npolitical department, said the Iranians had 15,000 casualties.\\n    Iran earlier today said its forces launched fresh attacks\\nnear Basra last night, adding that 1,200 Iraqis were killed or\\nwounded in fighting near Fish Lake, 10 km east of Basra.\\n    In its first reaction to Tehran reports of a new Iranian\\noffensive on the northern front, Iraq said fighting continues\\naround the strategic mountain peak of Kardamanend, overlooking\\nthe Haj Omran-Rawandiz axis close to the Iranian border.\\n    A military spokesman said Iran launched its attack in the\\nnorth \"to (turn) Iraqi attention towards that area and relax\\npressure in the south.\"\\n    He added, \"Iraq knows well that Iran\\'s main goal is to\\noccupy Basra in the south and that was the reason why Iraq has\\nrepelled their new offensive so decisively and firmly.\"\\n    Iran reported heavy fighting on both fronts today.\\n', 'Iran reported heavy fighting on both fronts today.\\n')\n('Bankers welcomed the Bank of Spain\\'s\\ndecision to raise the reserve requirement for banks and savings\\nbanks, saying it reflected the socialist government\\'s\\ndetermination not to ease up in the fight against inflation\\ndespite the painful social effects of four years of austerity.\\n    The central bank last night raised the requirement by one\\npercentage point to 19 pct from March 13, saying that excess\\nliquidity threatened money supply and inflation targets.\\n    Bankers said the move represented a change of tactic by the\\nBank, which until now has relied on raising interest rates to\\nchoke off money supply growth.\\n    \"I think it\\'s a good measure,\" a senior foreign banker said.\\n\"It\\'s a faster way to get the job done than using interest rates\\nand avoids unpleasant effects on other areas of the economy.\"\\n    \"It shows that the political will is very strong. They know\\nthat controlling inflation will make industry more competitive\\nand bring down unemployment in the long run,\" he added.\\n    The head of another foreign bank said that only a month\\nago, the Bank of Spain had dismissed his suggestion of a rise\\nin reserve requirements, preferring to pursue its strategy of\\nraising interest rates.\\n    But bankers said the high real interest rates on offer now\\n-- around eight pct for overnight funds -- was attracting money\\nfrom abroad, strengthening the peseta and making Spanish\\nexports less competitive.\\n    The government says industry\\'s competitiveness is also\\nbeing hit hard by inflation. At 8.3 pct last year, the rate was\\nway above that of Spain\\'s major trading partners in the\\nEuropean Community, which it joined a year ago.\\n    To help meet this year\\'s target of five pct, it is\\ninsisting pay rises stay at that level, setting the stage for\\nclashes with trade unions, who say they have made enough\\nsacrifices.\\n    Demonstrations by workers, students and farmers, whose\\ndemands essentially involve more government spending, have\\nbecome an almost daily occurrence. But Prime Minister Felipe\\nGonzalez insists that the state is doing as much as it can.\\n    Bankers said the reserve requirement increase could have\\nsome impact on commercial lending rates but should not hit the\\nmoney market too hard.\\n    The Bank of Spain, which only yesterday raised its key\\novernight call money rate to 13.5 pct, left it unchanged at\\ntoday\\'s auction. The rate has been increased nine times since\\nthe start of the year, when it was below 12 pct.\\n    Bankers said commercial lending rates were set to rise in\\nany case with the end of the six pct maximium interest rate\\nbanks can offer for time deposits of up to six months.\\n    The measure will take effect tomorrow, following the\\npublication of the decree in today\\'s official gazette. Bankers\\nsay the liberalisation will increase the cost of funds and,\\ninevitably, push lending rates higher.\\n    A companion measure, reducing the proportion of funds which\\nbanks must invest in specific areas, also takes effect\\ntomorrow. Officials said when the cut was approved last month\\nthat it was aimed partly at compensating banks for higher\\ninterest rates.\\n', 'interest rates.\\n')\n('Standard Oil Co and BP North America\\nInc said they plan to form a venture to manage the money market\\nborrowing and investment activities of both companies.\\n    BP North America is a subsidiary of British Petroleum Co\\nPlc &lt;BP>, which also owns a 55 pct interest in Standard Oil.\\n    The venture will be called BP/Standard Financial Trading\\nand will be operated by Standard Oil under the oversight of a\\njoint management committee.\\n', 'joint management committee.\\n')\n('&lt;America First Federally Guaranteed\\nMortgage Fund Two> said it is making a special distribution of\\n71.6 cts per exchangeable unit, which includes 67.62 cts from\\nreturn on capital and 3.98 cts from income gains.\\n', 'return on capital and 3.98 cts from income gains.\\n')\n"
    }
   ],
   "source": [
    "ui = Flask(__name__)\n",
    "x = []\n",
    "@ui.route('/')\n",
    "def index():\n",
    "    return render_template('base.html')\n",
    "\n",
    "\n",
    "@ui.route('/search', methods=['POST', 'GET'])\n",
    "def search():\n",
    "    if request.method == 'POST':\n",
    "        list_title = []\n",
    "        list_date = []\n",
    "        list_body =[]\n",
    "        search = request.form[\"search\"]\n",
    "        method = request.form.get('met')\n",
    "        result = request.form.get('res')\n",
    "        if method == \"1\":\n",
    "            start_time = time.time()\n",
    "            hasil, score = search_query(search, result)\n",
    "        else :\n",
    "            start_time = time.time()\n",
    "            rank = searchQuery('tf-idf.txt', search)\n",
    "            hasil, score = to_list(rank, result)\n",
    "        for i in hasil:\n",
    "            title, date, body = get_atribut(i)\n",
    "            list_title.append(title)\n",
    "            list_date.append(date)\n",
    "            list_body.append(body)\n",
    "        search = pre_query(search)\n",
    "        search2 = ' '.join(map(str, search))\n",
    "        # rec = calRecall(hasil, dict_jawaban.get(search2))\n",
    "        # prec = calPrecision(hasil, dict_jawaban.get(search2))\n",
    "        ptime = (time.time() - start_time)\n",
    "        return render_template('respond.html', title = list_title, date = list_date,body=list_body, score = score, leng = len(list_title), time = ptime)\n",
    "    else:\n",
    "        return render_template('index.html')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ui.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python37264bit69774f291abd483f85df9cd74e3c9e37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}