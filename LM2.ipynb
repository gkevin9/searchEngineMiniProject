{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_column_arr(data_frame, field, field_arr):\n",
    "    list_f_arr = []\n",
    "    dict_hasil = {}\n",
    "    f_arr = data_frame[field_arr]\n",
    "    for i in f_arr:\n",
    "        deleted_simbol = i.replace(\" \",\"\").replace(\"'\", \"\").replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "        temp = deleted_simbol.split(\",\")\n",
    "        \n",
    "#         dict_hasil[term[i]] = num_doc\n",
    "        list_f_arr.append(temp)\n",
    "    dict_hasil = {field: data_frame[field], field_arr:list_f_arr }\n",
    "    df = pd.DataFrame(dict_hasil)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baca File CSV yang Di Perlukan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   doc_num                                              token\n0        1  [0.39, 1, 750, 1, 780, 1, 850, 1, 870, 1, 875,...\n1        2  [15:02:20.00, 26-feb-1987, 55, activ, also, am...\n2        3  [13.5, 15:03:27.51, 26-feb-1987, 31, 7.5, appl...\n3        4  [-1, -20, 1, 11, 12, 15, 15:07:13.72, 2, 2.70,...\n4        5  [-1986, 0.99, 1, 1.24, 1.35, 1.56, 1.65, 1.92,...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_num</th>\n      <th>token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[0.39, 1, 750, 1, 780, 1, 850, 1, 870, 1, 875,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[15:02:20.00, 26-feb-1987, 55, activ, also, am...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[13.5, 15:03:27.51, 26-feb-1987, 31, 7.5, appl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[-1, -20, 1, 11, 12, 15, 15:07:13.72, 2, 2.70,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[-1986, 0.99, 1, 1.24, 1.35, 1.56, 1.65, 1.92,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_doc_num_token = pd.read_csv(\"doc_num_token.csv\")\n",
    "df_doc_num_token = conv_column_arr(df_doc_num_token,\"doc_num\",\"token\")\n",
    "df_doc_num_token.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   term                                            doc_num\n0    -1  [0004, 0008, 0016, 0026, 0059, 0059, 0059, 005...\n1   -10                                             [0305]\n2  -100                                             [0427]\n3   -11                                             [0116]\n4  -110                                             [0427]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>doc_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>[0004, 0008, 0016, 0026, 0059, 0059, 0059, 005...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-10</td>\n      <td>[0305]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-100</td>\n      <td>[0427]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-11</td>\n      <td>[0116]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-110</td>\n      <td>[0427]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df_token_doc_num = pd.read_csv(\"hasil_preprocessing.csv\")\n",
    "df_token_doc_num = conv_column_arr(df_token_doc_num, \"term\", \"doc_num\")\n",
    "df_token_doc_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "49088"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# menghitung jml token\n",
    "jml_token = 0\n",
    "for i in range(len(df_doc_num_token)):\n",
    "    jml_token += len(df_doc_num_token[\"token\"].iloc[i])\n",
    "jml_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi-fungsi untuk preprocessing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token(txt):\n",
    "    list_hasil = txt.split(\" \")            \n",
    "    return list_hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNull(listOfWords): #['','','eat','food','','']\n",
    "    listOfWords = list(filter(None, listOfWords))\n",
    "    \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caseFolding(listOfWords):\n",
    "    for i in range(len(listOfWords)):\n",
    "        listOfWords[i] = listOfWords[i].casefold()\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWord(listOfWords):\n",
    "    for i in listOfWords:\n",
    "        if i in stop_words:\n",
    "            listOfWords.remove(i)\n",
    "        \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(listOfWords):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for word in listOfWords]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fungsi utama main preprocessing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_query(txt):\n",
    "    listOfWords = make_token(txt)\n",
    "    listOfWords = removeNull(listOfWords)\n",
    "    listOfWords = caseFolding(listOfWords)\n",
    "    listOfWords = removeStopWord(listOfWords)\n",
    "    listOfWords = stemming(listOfWords)\n",
    "    \n",
    "    return listOfWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fungsi utama menghitung Score dokumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitung_score(list_word,a):\n",
    "    list_rank = []\n",
    "    list_doc_num2 = []\n",
    "    df_hasil = []\n",
    "    for i in range(len(df_doc_num_token)):\n",
    "        rank = 1\n",
    "        doc = df_doc_num_token.iloc[i]\n",
    "        for j in list_word:\n",
    "            count = doc[\"token\"].count(j)\n",
    "            panjang_doc = len(doc[\"token\"])\n",
    "            p_doc =  (count/panjang_doc) * a\n",
    "#           ----------------------------------\n",
    "            temp = df_token_doc_num[df_token_doc_num[\"term\"] == j]\n",
    "#             print(i, temp)\n",
    "            count_m = len(temp.iloc[0][1])\n",
    "            p_m = (count_m/jml_token) * (1-a)\n",
    "            p = p_doc + p_m\n",
    "            rank *= p\n",
    "        list_rank.append(rank)\n",
    "        list_doc_num2.append(doc[\"doc_num\"])\n",
    "    dict_hasil = {\"doc_num\": list_doc_num2, \"rank\": list_rank}\n",
    "    df_hasil = pd.DataFrame(dict_hasil)\n",
    "    df_hasil = df_hasil.sort_values(by=[\"rank\"], ignore_index=True, ascending=False)\n",
    "    return df_hasil\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coba query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"1991\"\n",
    "q2 = \"Dicounts\"\n",
    "q3 = \"accessed 9-Mar-87\"\n",
    "q4 = \"Analyst appeared\"\n",
    "q5 = \"Analyst analyst appeared\"\n",
    "q6 = \"Chairman closed the last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['dicount']"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "q = pre_query(q2)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hasil = hitung_score(q,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jawaban1 = [31, 61, 70, 105, 190, 301, 422, 466]\n",
    "jawaban2 = [77, 80, 97, 160, 195, 208, 215, 256, 488]\n",
    "jawaban3 = [32, 55, 110, 116, 134, 141, 142, 143, 144, 145, 146, 147, 148,\n",
    "            149, 150, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 261, \n",
    "            262, 263, 264, 265, 266, 267, 268, 269, 270, 321, 322, 323, 324, \n",
    "            325, 326, 327, 328, 329, 330, 348, 375, 381, 382, 383, 384, 385, \n",
    "            386, 387, 388, 389, 390, 441, 442, 443, 444, 445, 446, 447, 448,\n",
    "            449, 450]\n",
    "jawaban4 = [4, 8, 16, 18, 28, 45, 78, 95, 98, 111, 123, 133, 150, 180, 195, \n",
    "            235, 243, 262, 265, 292, 305, 320, 376, 399, 418, 459, 469, 493, \n",
    "            495, 496, 497]\n",
    "jawaban5 = [4, 8, 16, 18, 28, 45, 78, 95, 98, 111, 123, 133, 150, 180, 195, \n",
    "            235, 243, 262, 265, 292, 305, 320, 376, 399, 418, 459, 469, 493, \n",
    "            495, 496, 497]\n",
    "jawaban6 = [1, 12, 18, 26, 28, 40, 43, 47, 52, 60, 61, 69, 78, 95, 98, 102, \n",
    "           107, 111, 114, 116, 133, 134, 135, 136, 138, 145, 148, 150, 153, \n",
    "           154, 155, 156, 161, 169, 174, 178, 180, 188, 194, 195, 197, 201, \n",
    "           203, 204, 207, 208, 214, 216, 224, 227, 230, 231, 232, 233, 234, \n",
    "           235, 242, 246, 254, 255, 256, 259, 261, 262, 263, 265, 267, 268, \n",
    "           269, 276, 279, 284, 288, 292, 303, 306, 314, 316, 318, 322, 324, \n",
    "           328, 330, 338, 339, 340, 343, 350, 355, 367, 371, 372, 375, 376, \n",
    "           378, 382, 383, 386, 392, 399, 404, 405, 409, 419, 420, 425, 430, \n",
    "           438, 439, 441, 444, 445, 446, 447, 448, 451, 454, 455, 457, 458, \n",
    "           463, 484, 488, 491, 492, 494, 495, 496, 498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "teratas = df_hasil.head(len(jawaban1)).sort_values(by=[\"doc_num\"], ignore_index=True, ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "hasil_query = teratas[\"doc_num\"]\n",
    "salah = []\n",
    "\n",
    "for i in hasil_query:\n",
    "    if int(i) not in jawaban1:\n",
    "        salah.append(i)\n",
    "        \n",
    "len(salah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   doc_num      rank\n0       31  0.005721\n1       61  0.000714\n2       70  0.001218\n3      105  0.001516\n4      190  0.002438\n5      301  0.001728\n6      422  0.001062\n7      466  0.000959",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_num</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>0.005721</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>61</td>\n      <td>0.000714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>70</td>\n      <td>0.001218</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>105</td>\n      <td>0.001516</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>190</td>\n      <td>0.002438</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>301</td>\n      <td>0.001728</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>422</td>\n      <td>0.001062</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>466</td>\n      <td>0.000959</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "teratas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, url_for, redirect, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(search, res):\n",
    "    res2 = int(res)\n",
    "    list_hasil = []\n",
    "    list_score = []\n",
    "    q = pre_query(search)\n",
    "    df_hasil = hitung_score(q,0.1)\n",
    "    for i in range(0, res2):\n",
    "        list_hasil.append(df_hasil.iloc[i][\"doc_num\"])\n",
    "        list_score.append(df_hasil.iloc[i][\"rank\"])\n",
    "    return list_hasil, list_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText(file):\n",
    "    words = []\n",
    "    f = open(file, 'r') #open file\n",
    "    text = f.read()    \n",
    "    f.close()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atribut(doc_id):\n",
    "    int_doc_id = int(doc_id)\n",
    "    str_doc_id = str(int_doc_id)\n",
    "    n = 4 - len(str_doc_id)\n",
    "    doc = (\"0\"*n) + str_doc_id\n",
    "    file_path = \"DataRouter\\\\Doc\" + doc + \".txt\"\n",
    "    \n",
    "    txt = readText(file_path)\n",
    "    \n",
    "    titlePattern = \"<TITLE>(.+)</TITLE>\"\n",
    "    title = re.findall(titlePattern, txt)[0]\n",
    "    \n",
    "    datePattern = \"<DATE>(.+)</DATE>\"\n",
    "    date = re.findall(datePattern, txt)[0]\n",
    "    \n",
    "    return title, date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PUNYA BONTENG TF-IDF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchQuery(_dir, _query):\n",
    "    file = open(_dir,'r')\n",
    "    \n",
    "    listQuery = pre_query(_query)\n",
    "    \n",
    "    dictOfQuery = {}\n",
    "    textPerLine = file.readlines()\n",
    "    for line in textPerLine:\n",
    "        temp = line.split('\\t')\n",
    "        if temp[0] in listQuery:\n",
    "            addLineToDict(dictOfQuery, line)\n",
    "            \n",
    "#     for i in dictOfQuery:\n",
    "#         print(i,' : ',dictOfQuery[i])\n",
    "#     print('=======================')\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    dictOfRank = computeRank(dictOfQuery, listQuery)\n",
    "    \n",
    "    return dictOfRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLineToDict(_dict, _line):\n",
    "    tempList = _line.split('\\t')\n",
    "    term = tempList[0]\n",
    "    \n",
    "    \n",
    "    termWeigth = tempList[1]\n",
    "    termWeigth = termWeigth.replace(';\\n','')\n",
    "    termWeigth = termWeigth.split(';')\n",
    "    listTermTemp = []\n",
    "    for i in termWeigth:\n",
    "        i = i.replace('[','')\n",
    "        i = i.replace(']','')\n",
    "        i = i.replace(' ','')\n",
    "        i = i.split(',')\n",
    "        i = [int(i[0]),float(i[1])]\n",
    "\n",
    "        listTermTemp.append(i)\n",
    "        \n",
    "    _dict[term] = listTermTemp\n",
    "    \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeRank(_dictTerm, _query):\n",
    "    dictQuery = countQuery(_query)\n",
    "    dictSumOfSim = {}\n",
    "    dictSumWeigthOfSim = {}\n",
    "#     print(dictQuery)\n",
    "    for i in _dictTerm:\n",
    "        ni = len(_dictTerm[i])\n",
    "        countWq = countWeigth(ni, dictQuery[i])\n",
    "#         print(countWq)\n",
    "        for k in _dictTerm[i]:\n",
    "            if k[0] in dictSumOfSim:\n",
    "                dictSumOfSim[k[0]] += k[1]**2 \n",
    "            else:\n",
    "                dictSumOfSim[k[0]] = k[1]**2\n",
    "                \n",
    "            if k[0] in dictSumWeigthOfSim:\n",
    "                dictSumWeigthOfSim[k[0]] += countWq * (k[1]**2) \n",
    "            else:\n",
    "                dictSumWeigthOfSim[k[0]] = countWq * (k[1]**2)\n",
    "                \n",
    "#     print(dictSumOfSim)\n",
    "#     print(dictSumWeigthOfSim)\n",
    "                \n",
    "    dictSqrtOfSim = findSqrt(dictSumOfSim)\n",
    "    \n",
    "    dictOfRank = findRank(dictSqrtOfSim, dictSumWeigthOfSim)\n",
    "    \n",
    "    return dictOfRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countQuery(_query):\n",
    "    dictOfQuery = {}\n",
    "    for i in _query:\n",
    "        if i in dictOfQuery:\n",
    "            dictOfQuery[i] += 1\n",
    "        else:\n",
    "            dictOfQuery[i] = 1\n",
    "            \n",
    "    return dictOfQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRank(_dictSqrt, _dictWeigth):\n",
    "#     print('sqrt : ',_dictSqrt)\n",
    "#     print('weigth : ',_dictWeigth)\n",
    "    dictOfRank = {}\n",
    "    for i in _dictSqrt:\n",
    "        dictOfRank[i] = (_dictWeigth[i]/_dictSqrt[i])\n",
    "        \n",
    "    return({k: v for k, v in sorted(dictOfRank.items(), key=lambda item: item[1], reverse=True)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def findSqrt(_dict):\n",
    "    for i in _dict:\n",
    "        _dict[i] = math.sqrt(_dict[i])\n",
    "    \n",
    "    return _dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWeigth(_ni, _fij):\n",
    "    \n",
    "    file = open('sum_of_file.txt','r')\n",
    "    sumOfFile = int(file.read())\n",
    "    file.close()\n",
    "    \n",
    "    tf = computeTFLog(_fij)\n",
    "    idf = countIDF(sumOfFile, _ni)\n",
    "    weigth = tf * idf\n",
    "    weigth = weigth**2\n",
    "    \n",
    "    return weigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#tf = 1 + log(i,j)\n",
    "def computeTFLog(_fi):\n",
    "    return 1 + math.log(_fi,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#idf = log(N/ni)\n",
    "def countIDF(_N, _ni):\n",
    "#     print('N : ',_N)\n",
    "#     print('_ni : ',_ni)\n",
    "    return math.log(1+(_N/_ni),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--- 0.018950700759887695 seconds ---\nRank :  {97: 510.75683569545686, 80: 395.175431406038, 77: 197.587715703019, 160: 197.587715703019, 195: 197.587715703019, 208: 197.587715703019, 215: 197.587715703019, 256: 197.587715703019, 488: 33.92396659928883}\n"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "rank = searchQuery('tf-idf.txt', 'Discount')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Rank : ', rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(rank, res):\n",
    "    res2 = int(res)\n",
    "    doc = []\n",
    "    score = []\n",
    "    doc2 = []\n",
    "    score2 = []\n",
    "    for x in rank:\n",
    "        doc.append(x)\n",
    "        score.append(rank[x])\n",
    "    if len(doc) > res2:\n",
    "        for i in range(0, res2):\n",
    "            doc2.append(doc[i])\n",
    "            score2.append(score[i])\n",
    "        return doc2, score2\n",
    "    else:\n",
    "        return doc, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>================</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "* Serving Flask app \"__main__\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n127.0.0.1 - - [23/Apr/2020 00:23:32] \"\u001b[37mGET /search HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [23/Apr/2020 00:23:38] \"\u001b[37mPOST /search HTTP/1.1\u001b[0m\" 200 -\n127.0.0.1 - - [23/Apr/2020 00:23:50] \"\u001b[37mPOST /search HTTP/1.1\u001b[0m\" 200 -\n"
    }
   ],
   "source": [
    "ui = Flask(__name__)\n",
    "x = []\n",
    "@ui.route('/')\n",
    "def index():\n",
    "    return render_template('base.html')\n",
    "\n",
    "\n",
    "@ui.route('/search', methods=['POST', 'GET'])\n",
    "def search():\n",
    "    if request.method == 'POST':\n",
    "        list_title = []\n",
    "        list_date = []\n",
    "        search = request.form[\"search\"]\n",
    "        method = request.form.get('met')\n",
    "        result = request.form.get('res')\n",
    "        if method == \"1\":\n",
    "            start_time = time.time()\n",
    "            hasil, score = search_query(search, result)\n",
    "        else :\n",
    "            start_time = time.time()\n",
    "            rank = searchQuery('tf-idf.txt', search)\n",
    "            hasil, score = to_list(rank, result)\n",
    "        for i in hasil:\n",
    "            title, date = get_atribut(i)\n",
    "            list_title.append(title)\n",
    "            list_date.append(date)\n",
    "        ptime = (time.time() - start_time)\n",
    "        return render_template('respond.html', title = list_title, date = list_date, score = score, leng = len(list_title), time = ptime)\n",
    "    else:\n",
    "        return render_template('index.html')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    ui.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "language": "python",
   "name": "python37264bit69774f291abd483f85df9cd74e3c9e37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}